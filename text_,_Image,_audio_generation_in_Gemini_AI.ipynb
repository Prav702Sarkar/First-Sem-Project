{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prav702Sarkar/First-Sem-Project/blob/main/text_%2C_Image%2C_audio_generation_in_Gemini_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###What is a prompt\n",
        "A prompt is a natural language request submitted to a language model to receive a response back. Prompts can contain questions, instructions, contextual information, examples, and partial input for the model to complete or continue. After the model receives a prompt, depending on the type of model being used, it can generate text, embeddings, code, images, videos, music, and more."
      ],
      "metadata": {
        "id": "S1bXrR1d0BSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-generativeai"
      ],
      "metadata": {
        "id": "FhHhLwiwPoeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "genai.configure(api_key=\"AIzaSyDC5q9UaLRf_zS7gcNesZ4uqCnmjZPdlwI\")\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "response = model.generate_content(\"Write about a the royal enfield brand\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "e1LcdVAsP-Hs",
        "outputId": "7cc0bad6-c2f2-414b-d6d6-2b0a788de874"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Royal Enfield, more than just a motorcycle brand, is a legend woven into the fabric of motorcycling history.  Founded in 1893 in Redditch, England, the company's journey has been one of remarkable resilience, shifting from a pioneering manufacturer of bicycles and early motorcycles to an iconic global player.  While the original British company ceased production in 1970, the brand was resurrected and revitalized in India, becoming synonymous with a specific riding experience and a passionate community.\n",
            "\n",
            "Royal Enfield's appeal lies in its deliberate rejection of modern trends in favour of a classic, almost nostalgic aesthetic.  Their bikes are characterized by their robust, thumping single-cylinder engines – a sound that has become deeply associated with the brand and is a major part of its charm for riders.  These are not bikes designed for speed demons; they're machines that prioritize a leisurely, engaging ride, inviting riders to connect with the road and their surroundings.\n",
            "\n",
            "The current Royal Enfield lineup showcases a diverse range of models, each capturing a different facet of the brand's legacy.  From the classic Bullet, a near-unmodified design echoing the company's heritage, to the more modern Interceptor and Continental GT, which blend vintage style with contemporary engineering, there's a Royal Enfield to suit a range of tastes.  However, a common thread runs through all their models: a focus on quality, durability, and a strong sense of character.\n",
            "\n",
            "Beyond the machines themselves, Royal Enfield fosters a unique community.  Owners often speak of the brand as more than just a purchase; it's a lifestyle.  The distinctive \"thump\" of their engines serves as a common language amongst riders, forging a sense of camaraderie on the road and at various enthusiast gatherings. This community aspect contributes significantly to the brand's enduring popularity.\n",
            "\n",
            "While the brand enjoys significant success in emerging markets, particularly in India, it's increasingly making inroads into Western markets, attracting riders who appreciate its unique blend of vintage charm and modern practicality.  The appeal transcends simple transportation; it's about experiencing the romance of the road, embracing a slower pace, and becoming part of a rich and enduring heritage.  Royal Enfield isn't just a motorcycle; it's a statement.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case, the prompt (\"Write a story about a magic backpack\") doesn't include any output examples, system instructions, or formatting information. It's a zero-shot approach. For some use cases, a one-shot or few-shot prompt might produce output that's more aligned with user expectations. In some cases, you might also want to provide system instructions to help the model understand the task or follow specific guidelines."
      ],
      "metadata": {
        "id": "xMyWazJRStWS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Generate text from text-and-image input\n",
        "\n",
        "The Gemini API supports multimodal inputs that combine text with media files. The following example shows how to generate text from text-and-image input:"
      ],
      "metadata": {
        "id": "IVXLYHCiS52_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "import PIL.Image\n",
        "\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "organ = PIL.Image.open(\"/content/drive/MyDrive/Colab Notebooks/avg.png\")\n",
        "response = model.generate_content([\"Tell me about this image\", organ])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "cde_zbJZS5bz",
        "outputId": "cadf7d06-23ef-47f6-cdd8-be88dd6840c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "That's promotional artwork for *The Avengers* (2012) film.  It depicts many of the main characters in the film in a dynamic action pose amidst a scene of destruction.\n",
            "\n",
            "Specifically, we see:\n",
            "\n",
            "* **Central Figures:**  Iron Man (two versions), Captain America, Hulk (two versions), and Black Widow are prominently featured in the forefront.\n",
            "\n",
            "* **Supporting Characters:** Other Avengers, including Thor (though not very visible), Hawkeye, and some other less prominent characters are shown in the background.\n",
            "\n",
            "* **Setting:** The background features a destroyed city, likely New York City, suggesting a battle scene.\n",
            "\n",
            "The overall style is high-energy and dramatic, typical of superhero movie marketing.  The color palette uses contrasting reds, blues, and greens of the costumes against the grey and brown tones of the ruined city.  The composition aims to showcase the power and teamwork of the Avengers.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwZtZr6T_rfq",
        "outputId": "2ffefede-f71f-4b61-e8a2-77282d4fe463"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Generate a text stream\n",
        "By default, the model returns a response after completing the entire text generation process. You can achieve faster interactions by not waiting for the entire result, and instead use streaming to handle partial results.\n",
        "\n",
        "The following example shows how to implement streaming using the streamGenerateContent method to generate text from a text-only input prompt."
      ],
      "metadata": {
        "id": "6rN7lWFKcj9C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the context of programming and data processing, a \"chunk\" refers to a smaller, manageable piece of data that is part of a larger dataset or stream. The term is often used when working with large files, streams, or real-time data where handling the entire dataset at once would be inefficient or impractical.\n",
        "\n",
        "Meaning of \"Chunk\" in Different Contexts\n",
        "Data Streaming:\n",
        "\n",
        "In APIs that stream data (like the example in your code), a chunk is a segment of the response received from the server in real time.\n",
        "For example, when generating text, instead of waiting for the entire output, the AI sends back smaller portions of the text (chunks) as they are ready."
      ],
      "metadata": {
        "id": "P7ooLXOgdYeK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "response = model.generate_content(\"Write a story about the race of the hare and the turtle.\", stream=True)\n",
        "for chunk in response:\n",
        "    print(chunk.text)\n",
        "    print(\"_\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        },
        "id": "2vMOZxEoVhL7",
        "outputId": "d1333210-8f3d-43de-b2ce-2108b1512659"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The\n",
            "________________________________________________________________________________\n",
            " sun beat down on the dusty track, baking the earth to a shimmering haze.\n",
            "________________________________________________________________________________\n",
            "  This was it – the annual Great Forest Race.  On one side,\n",
            "________________________________________________________________________________\n",
            " a blur of white fur, Hare, boasted a cocky grin. His muscles rippled beneath sleek fur, his long ears twitching with anticipation. Opposite him,\n",
            "________________________________________________________________________________\n",
            " Turtle, his shell gleaming dully under the harsh light, stood with unwavering resolve, his small, wise eyes fixed on the starting line.\n",
            "\n",
            "The starting pistol\n",
            "________________________________________________________________________________\n",
            " cracked, a tiny sound swallowed by the roar of the assembled animals. Hare shot forward like an arrow, a brown streak against the ochre landscape. He left Turtle in the dust, a tiny speck disappearing behind a cloud of his own speed.\n",
            "________________________________________________________________________________\n",
            "  The crowd, a chaotic blend of foxes, badgers, and squirrels, erupted in cheers.  Hare, confident and arrogant, glanced back – a fatal mistake.  Turtle was still a distant dot, barely moving.\n",
            "\n",
            "Hare,\n",
            "________________________________________________________________________________\n",
            " convinced of his effortless victory, found a shady patch beneath a sprawling oak tree.  “I’ll just have a little nap,” he muttered, stretching out luxuriously. The sweet scent of wildflowers lulled him into a deep, dreamless sleep.\n",
            "\n",
            "Meanwhile, Turtle plodded on, his movements slow but\n",
            "________________________________________________________________________________\n",
            " steady, persistent as the relentless sun.  He didn’t rush; he didn’t stop.  He just kept moving, one determined step after another.  He passed the giggling squirrels, the gossiping foxes, the cheering badgers – all oblivious to the sleeping hare.  He saw the shimmering heat haze\n",
            "________________________________________________________________________________\n",
            " distort the landscape ahead, but his focus remained unyielding.\n",
            "\n",
            "Hours crawled by.  The sun began its slow descent, casting long shadows across the track.  Hare finally awoke, his eyes blinking sleepily in the fading light.  He looked around, a jolt of panic shooting through him.  Where was everyone\n",
            "________________________________________________________________________________\n",
            "?  He saw Turtle, a mere fifty yards from the finish line, his tiny legs moving with the same unwavering rhythm.\n",
            "\n",
            "Panic fueled Hare’s run. He was fast, unbelievably fast.  He stretched out his powerful legs, the wind whipping through his fur.  But it wasn't enough.  \n",
            "________________________________________________________________________________\n",
            "Turtle, despite his slow pace, had maintained a constant speed.  The gap was too much to close.\n",
            "\n",
            "As the sun dipped below the horizon, painting the sky in fiery hues, Turtle crossed the finish line, a small, triumphant squeak escaping his shell.  The crowd roared with a mixture of surprise and admiration\n",
            "________________________________________________________________________________\n",
            ".  Hare, panting and exhausted, arrived moments later, his arrogance replaced with a profound understanding.\n",
            "\n",
            "The moral of the story, the wise old owl hooted from a nearby branch, wasn't just about speed.  It was about consistency, perseverance, and the unwavering pursuit of one’s goal, even\n",
            "________________________________________________________________________________\n",
            " if it takes a little longer.  Hare learned a valuable lesson that day – a lesson etched not in the dust of the race track, but in the humbling reality of his defeat.  And though he was fast, it was Turtle who truly won the race.\n",
            "\n",
            "________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Build an interactive chat\n",
        "You can use the Gemini API to build interactive chat experiences for your users. Using the chat feature of the API lets you collect multiple rounds of questions and responses, allowing users to step incrementally toward answers or get help with multipart problems. This feature is ideal for applications that require ongoing communication, such as chatbots, interactive tutors, or customer support assistants.\n",
        "\n",
        "The following code example shows a basic chat implementation:"
      ],
      "metadata": {
        "id": "t9Y2h4UuW8fO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "chat = model.start_chat(\n",
        "    history=[\n",
        "        {\"role\": \"user\", \"parts\": \"Hello\"},\n",
        "        {\"role\": \"model\", \"parts\": \"Great to meet you. What would you like to know?\"},\n",
        "    ]\n",
        ")\n",
        "response = chat.send_message(\"I have a black and white jacket.\")\n",
        "print(response.text)\n",
        "response = chat.send_message(\"How many color combinations are their for the design of jacket?\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "6q5AjQs9XB1B",
        "outputId": "d0a93b48-d37b-46ee-a59b-088ee2a988fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "That's nice!  Is it a monochrome pattern, or are there distinct black and white sections?  What's it made of?  What style is it?  Tell me more!\n",
            "\n",
            "That depends entirely on how you define \"color combination\" in the context of a jacket design.  Are we talking about:\n",
            "\n",
            "* **Just the main colors?**  If the jacket is only black and white, then there's only one main color combination: black and white.\n",
            "\n",
            "* **Different patterns using black and white?** This opens up a vast number of possibilities – stripes, checks, polka dots, abstract designs, etc.  There are literally millions, if not infinite, possibilities depending on the complexity of the pattern.\n",
            "\n",
            "* **Including other design elements?**  If you consider things like the type of fabric (e.g., different textures), stitching, buttons, zippers, and other details, the number of combinations becomes astronomically large.\n",
            "\n",
            "To give you a meaningful answer, I need more specific parameters.  How detailed should the analysis be?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "myfile = genai.upload_file(\"/content/drive/MyDrive/Colab Notebooks/meow.mp3\")\n",
        "print(f\"{myfile=}\")\n",
        "\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "result = model.generate_content([myfile, \"Describe this audio clip\"])\n",
        "print(f\"{result.text=}\")"
      ],
      "metadata": {
        "id": "8yw6Jow7fV5_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "47ec5142-23bc-40c8-d96e-eb3e91bbdbe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "myfile=genai.File({\n",
            "    'name': 'files/a27xlf753asi',\n",
            "    'display_name': 'meow.mp3',\n",
            "    'mime_type': 'audio/mpeg',\n",
            "    'sha256_hash': 'MjkyNGEzNDgyYjFkMjQ0NGI5MGNjMTZmOWUzN2U1ZjVhMjUzN2UxMTI5ZGI1MDdlNzgxMmIxYTA1NDYyYmVlOQ==',\n",
            "    'size_bytes': '213148',\n",
            "    'state': 'ACTIVE',\n",
            "    'uri': 'https://generativelanguage.googleapis.com/v1beta/files/a27xlf753asi',\n",
            "    'create_time': '2024-12-02T14:35:21.513762Z',\n",
            "    'expiration_time': '2024-12-04T14:35:21.452338782Z',\n",
            "    'update_time': '2024-12-02T14:35:21.513762Z'})\n",
            "result.text=\"That audio clip is a cat meowing.  It's a series of meows of varying lengths and pitches, characteristic of a cat vocalization.\\n\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U git+https://github.com/google-gemini/generative-ai-python@imagen"
      ],
      "metadata": {
        "id": "eP_E-9H3tg-U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 966
        },
        "outputId": "db08f609-9948-4d06-f1b2-04d953a0d6db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/google-gemini/generative-ai-python@imagen\n",
            "  Cloning https://github.com/google-gemini/generative-ai-python (to revision imagen) to /tmp/pip-req-build-doxs1p6y\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/google-gemini/generative-ai-python /tmp/pip-req-build-doxs1p6y\n",
            "  Running command git checkout -b imagen --track origin/imagen\n",
            "  Switched to a new branch 'imagen'\n",
            "  Branch 'imagen' set up to track remote branch 'imagen' from 'origin'.\n",
            "  Resolved https://github.com/google-gemini/generative-ai-python to commit 2786f33edbabc441b247e549025b3e9e5e849895\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in /usr/local/lib/python3.10/dist-packages (from google-generativeai==0.8.2) (0.6.10)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai==0.8.2) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai==0.8.2) (2.151.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai==0.8.2) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai==0.8.2) (4.25.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai==0.8.2) (2.9.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai==0.8.2) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai==0.8.2) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.10->google-generativeai==0.8.2) (1.25.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai==0.8.2) (1.66.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai==0.8.2) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai==0.8.2) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai==0.8.2) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai==0.8.2) (4.9)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai==0.8.2) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai==0.8.2) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai==0.8.2) (4.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai==0.8.2) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai==0.8.2) (2.23.4)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai==0.8.2) (1.68.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai==0.8.2) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai==0.8.2) (3.2.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai==0.8.2) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai==0.8.2) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai==0.8.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai==0.8.2) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai==0.8.2) (2024.8.30)\n",
            "Building wheels for collected packages: google-generativeai\n",
            "  Building wheel for google-generativeai (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-generativeai: filename=google_generativeai-0.8.2-py3-none-any.whl size=161059 sha256=0430d97dcf13368abac437eb9ae8b8dd80189d79e147878e8b293d6111bb7bfb\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7e46s5zl/wheels/dc/8f/91/437bbb0d80260245a962e8cf6eaacbb34c4cbe50698c277acf\n",
            "Successfully built google-generativeai\n",
            "Installing collected packages: google-generativeai\n",
            "  Attempting uninstall: google-generativeai\n",
            "    Found existing installation: google-generativeai 0.8.3\n",
            "    Uninstalling google-generativeai-0.8.3:\n",
            "      Successfully uninstalled google-generativeai-0.8.3\n",
            "Successfully installed google-generativeai-0.8.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "842aac55ee714e1d96079f92fb665f65"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DAWR2M0uEOne"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}